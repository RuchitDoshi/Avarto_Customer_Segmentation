{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn .pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv('../capstone_data/Udacity_MAILOUT_052018_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('../capstone_data/Udacity_MAILOUT_052018_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1763</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1771</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  1763         2         1.0       8.0          NaN          NaN   \n",
       "1  1771         1         4.0      13.0          NaN          NaN   \n",
       "2  1776         1         1.0       9.0          NaN          NaN   \n",
       "3  1460         2         1.0       6.0          NaN          NaN   \n",
       "4  1783         2         1.0       9.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                   8.0                 15.0  ...   \n",
       "1          NaN          NaN                  13.0                  1.0  ...   \n",
       "2          NaN          NaN                   7.0                  0.0  ...   \n",
       "3          NaN          NaN                   6.0                  4.0  ...   \n",
       "4          NaN          NaN                   9.0                 53.0  ...   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       5.0         2.0      1.0             6.0             9.0       3.0   \n",
       "1       1.0         2.0      1.0             4.0             9.0       7.0   \n",
       "2       6.0         4.0      2.0             NaN             9.0       2.0   \n",
       "3       8.0        11.0     11.0             6.0             9.0       1.0   \n",
       "4       2.0         2.0      1.0             6.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP RESPONSE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         3        0         2                    4  \n",
       "1         1        0         2                    3  \n",
       "2         3        0         1                    4  \n",
       "3         3        0         2                    4  \n",
       "4         3        0         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attribute_Unknown_Dict(path,df):\n",
    "    '''\n",
    "    Purpose: Map all the attributes to their unknown values in a dictionary\n",
    "    \n",
    "    Input: PATH TO DIAS Attributes - Values 2017.xlsx file, in str format\n",
    "    \n",
    "    Output:\n",
    "    new_dict:Dictionary with attributes as key and the unknown meaning values in a list\n",
    "    '''\n",
    "    #reading the xlsx file and storing it in a dataframe\n",
    "    attributes=pd.read_excel(path,skiprows=1)\n",
    "    \n",
    "    #formatting\n",
    "    attributes=attributes.drop(['Unnamed: 0'],axis=1,inplace=False)\n",
    "    \n",
    "    #Droping all the rows with nan values. Since, all the first values refer to the unknown meaning category\\\n",
    "    #Only keeping the first row for each attribute works\n",
    "    attributes=attributes.dropna()\n",
    "    \n",
    "    new_dict={}\n",
    "    for i in range(attributes.shape[0]):\n",
    "        #checking if it corresponds to the unknown value\n",
    "        if ('unknown' in attributes['Meaning'].iloc[i].split()) or(attributes['Meaning'].iloc[i] == 'no transaction known'):\n",
    "            new_list=[]\n",
    "            if type(attributes['Value'].iloc[i])==int:\n",
    "                new_list.append(attributes['Value'].iloc[i])\n",
    "            else:\n",
    "                for j in attributes['Value'].iloc[i].split(','):\n",
    "                    new_list.append(int(j))\n",
    "\n",
    "            new_dict[attributes['Attribute'].iloc[i]]=new_list\n",
    "    \n",
    "    #These columns are not present in  the actual dataset\n",
    "    new_dict.pop('BIP_FLAG')\n",
    "    new_dict.pop('GEOSCORE_KLS7')\n",
    "    new_dict.pop('HAUSHALTSSTRUKTUR')\n",
    "    new_dict.pop('SOHO_FLAG')\n",
    "    new_dict.pop('WACHSTUMSGEBIET_NB')\n",
    "    \n",
    "    \n",
    "    #Removing name '_RZ' from the end of each column name\n",
    "    for i in new_dict:\n",
    "        if i not in df.columns:\n",
    "            new_dict[i[:-3]]=new_dict.pop(i)\n",
    "    \n",
    "    #removing the last key_value pair\n",
    "    new_dict.pop('')\n",
    "    \n",
    "    \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Map_unknown_to_NAN(df,attribute_dict):\n",
    "    '''\n",
    "    Replace the unknown values with NAN values in the df\n",
    "    ARGS:\n",
    "    df: Dataframe on which the mapping takes place like azdias\n",
    "    attribute_dict: Dict with attribute as keys and values which are to replaced with NAN\n",
    "    \n",
    "    Output:\n",
    "    df: transformed df with more null values\n",
    "    \n",
    "    '''\n",
    "    #Replacing \n",
    "    for key,val in attribute_dict.items():\n",
    "        for j in val:\n",
    "            df[key]=df[key].replace(j,np.nan)\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num(df):\n",
    "    '''\n",
    "    converting columns which are categorical to numerical and droping other categorical columns\n",
    "    INput: \n",
    "    df: DataFrame to be processed\n",
    "    \n",
    "    Output:\n",
    "    df: After droping and converting categorical columns\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #converting CAMEO_INTL_2015 AND CAMEO_DEUB_2015 into numerical values\n",
    "    intl=[]\n",
    "    deug=[]\n",
    "    for i in range(len(df['CAMEO_INTL_2015'])):\n",
    "        if type(df['CAMEO_INTL_2015'].iloc[i])==str and df['CAMEO_INTL_2015'].iloc[i][0]=='X':\n",
    "            intl.append(np.nan)\n",
    "        else:\n",
    "            intl.append(float(df['CAMEO_INTL_2015'].iloc[i]))\n",
    "        if type(df['CAMEO_INTL_2015'].iloc[i])==str and df['CAMEO_DEUG_2015'].iloc[i][0]=='X':\n",
    "            deug.append(np.nan)\n",
    "        else:\n",
    "            deug.append(float(df['CAMEO_DEUG_2015'].iloc[i]))\n",
    "    \n",
    "    #droping the original columns\n",
    "    df=df.drop(['CAMEO_INTL_2015','CAMEO_DEUG_2015'],axis=1,inplace=False)\n",
    "    #Adding new columns\n",
    "    df['CAMEO_INTL_2015']=intl\n",
    "    df['CAMEO_DEUG_2015']=deug\n",
    "    \n",
    "    #droping 'LNR' AND 'VERDICHTUNGSRAUM' columns\n",
    "    #droping the 'LP_FAMILIE_GROB' column because it very similar 'LP_FAMILIE_FEIN'\n",
    "\n",
    "    df=df.drop(['LNR','VERDICHTUNGSRAUM','LP_FAMILIE_GROB'],axis=1,inplace=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_categories(df):\n",
    "    '''\n",
    "    Spliting mixed attributes into individua;\n",
    "    Input:\n",
    "    df: DataFrame to be processed\n",
    "    \n",
    "    Output:\n",
    "    df\n",
    "    '''\n",
    "    \n",
    "    df['WEALTH']=df['CAMEO_INTL_2015'].apply(lambda x:x/10)\n",
    "    df['LIFE_CYCLE']=df['CAMEO_INTL_2015'].apply(lambda x:x%10)\n",
    "    \n",
    "    mainstream=[1.0, 3.0, 5.0, 8.0, 10.0, 12.0, 14.0]\n",
    "    avantgarde=[2.0, 4.0, 6.0, 7.0, 9.0, 11.0, 13.0, 15.0]\n",
    "    \n",
    "    main=df['PRAEGENDE_JUGENDJAHRE'].isin([1.0, 3.0, 5.0, 8.0, 10.0, 12.0, 14.0])\n",
    "    avar=df['PRAEGENDE_JUGENDJAHRE'].isin([2.0, 4.0, 6.0, 7.0, 9.0, 11.0, 13.0, 15.0])\n",
    "    \n",
    "    df.loc[main,'MOVEMENT']=1.0\n",
    "    df.loc[avar,'MOVEMENT']=2.0\n",
    "    \n",
    "    df=df.drop(['CAMEO_INTL_2015','PRAEGENDE_JUGENDJAHRE', 'EINGEFUEGT_AM','D19_LETZTER_KAUF_BRANCHE'],axis=1,inplace=False)\n",
    "    \n",
    "    df['OST_WEST_KZ'] = df['OST_WEST_KZ'].replace({'O':1.0, 'W':2.0})\n",
    "    \n",
    "    new_df=pd.get_dummies(df,columns=['CAMEO_DEU_2015'])\n",
    "    \n",
    "    new_df=new_df.drop(['CAMEO_DEU_2015_XX'],axis=1,inplace=False)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df):\n",
    "    '''\n",
    "    Replacing all the null values with mean of the column\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    fill_mean=lambda col:col.fillna(col.mean())\n",
    "    df=df.apply(fill_mean,axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing RESPONSE column from Training_data and storing it in train_labels\n",
    "train_labels=train_data['RESPONSE']\n",
    "train_data=train_data.drop(['RESPONSE'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing cleaning functions (same as preprocessing)\n",
    "attribute_dict=Attribute_Unknown_Dict('../capstone_data/DIAS Attributes - Values 2017.xlsx',train_data)\n",
    "train_data=Map_unknown_to_NAN(train_data,attribute_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing the columns with more than 50% of null values and droping it from training_df\n",
    "drop_cols=list(train_data.isnull().sum(axis=0)[train_data.isnull().sum(axis=0)>0.50*(train_data.shape[0])]\\\n",
    "                    .reset_index()['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing cleaning functions (same as preprocessing)\n",
    "train_data=train_data.drop(columns=drop_cols,axis=1,inplace=False)\n",
    "train_data=cat_to_num(train_data)\n",
    "train_data=mixed_categories(train_data)\n",
    "train_data=impute(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>CAMEO_DEU_2015_7E</th>\n",
       "      <th>CAMEO_DEU_2015_8A</th>\n",
       "      <th>CAMEO_DEU_2015_8B</th>\n",
       "      <th>CAMEO_DEU_2015_8C</th>\n",
       "      <th>CAMEO_DEU_2015_8D</th>\n",
       "      <th>CAMEO_DEU_2015_9A</th>\n",
       "      <th>CAMEO_DEU_2015_9B</th>\n",
       "      <th>CAMEO_DEU_2015_9C</th>\n",
       "      <th>CAMEO_DEU_2015_9D</th>\n",
       "      <th>CAMEO_DEU_2015_9E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  \\\n",
       "0       2.0         1.0       8.0                   8.0                 15.0   \n",
       "1       1.0         4.0      13.0                  13.0                  1.0   \n",
       "2       1.0         1.0       9.0                   7.0                  0.0   \n",
       "3       2.0         1.0       6.0                   6.0                  4.0   \n",
       "4       2.0         1.0       9.0                   9.0                 53.0   \n",
       "\n",
       "   ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  \\\n",
       "0      0.000000         0.0           1.0                        13.0   \n",
       "1      0.000000         0.0           2.0                         1.0   \n",
       "2      0.049574         0.0           0.0                         1.0   \n",
       "3      0.000000         0.0           2.0                         4.0   \n",
       "4      0.000000         0.0           1.0                        44.0   \n",
       "\n",
       "   ANZ_TITEL  ...  CAMEO_DEU_2015_7E  CAMEO_DEU_2015_8A  CAMEO_DEU_2015_8B  \\\n",
       "0        0.0  ...                  0                  0                  0   \n",
       "1        0.0  ...                  0                  0                  0   \n",
       "2        0.0  ...                  0                  0                  0   \n",
       "3        0.0  ...                  0                  0                  0   \n",
       "4        0.0  ...                  0                  0                  0   \n",
       "\n",
       "   CAMEO_DEU_2015_8C  CAMEO_DEU_2015_8D  CAMEO_DEU_2015_9A  CAMEO_DEU_2015_9B  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   CAMEO_DEU_2015_9C  CAMEO_DEU_2015_9D  CAMEO_DEU_2015_9E  \n",
       "0                  0                  0                  0  \n",
       "1                  0                  0                  0  \n",
       "2                  0                  0                  0  \n",
       "3                  0                  0                  0  \n",
       "4                  0                  0                  0  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the LNR column for submission on Kaggle\n",
    "test_lnr=test_data['LNR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data=Map_unknown_to_NAN(test_data,attribute_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping the same columns from testing data \n",
    "test_data=test_data.drop(columns=drop_cols,axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing cleaning functions (same as preprocessing)\n",
    "test_data=cat_to_num(test_data)\n",
    "test_data=mixed_categories(test_data)\n",
    "test_data=impute(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>CAMEO_DEU_2015_7E</th>\n",
       "      <th>CAMEO_DEU_2015_8A</th>\n",
       "      <th>CAMEO_DEU_2015_8B</th>\n",
       "      <th>CAMEO_DEU_2015_8C</th>\n",
       "      <th>CAMEO_DEU_2015_8D</th>\n",
       "      <th>CAMEO_DEU_2015_9A</th>\n",
       "      <th>CAMEO_DEU_2015_9B</th>\n",
       "      <th>CAMEO_DEU_2015_9C</th>\n",
       "      <th>CAMEO_DEU_2015_9D</th>\n",
       "      <th>CAMEO_DEU_2015_9E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.651514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.433248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.651514</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.433248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGER_TYP  AKT_DAT_KL   ALTER_HH  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  \\\n",
       "0  2.000000         1.0   7.000000                   6.0                  2.0   \n",
       "1  1.651514         1.0  12.433248                   0.0                 20.0   \n",
       "2  2.000000         9.0  16.000000                  11.0                  2.0   \n",
       "3  1.651514         7.0  12.433248                   0.0                  1.0   \n",
       "4  1.000000         1.0  21.000000                  13.0                  1.0   \n",
       "\n",
       "   ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  \\\n",
       "0           0.0         0.0           2.0                         2.0   \n",
       "1           0.0         0.0           1.0                        21.0   \n",
       "2           0.0         0.0           4.0                         2.0   \n",
       "3           0.0         0.0           0.0                         1.0   \n",
       "4           0.0         0.0           4.0                         1.0   \n",
       "\n",
       "   ANZ_TITEL  ...  CAMEO_DEU_2015_7E  CAMEO_DEU_2015_8A  CAMEO_DEU_2015_8B  \\\n",
       "0        0.0  ...                  0                  0                  0   \n",
       "1        0.0  ...                  0                  0                  0   \n",
       "2        0.0  ...                  0                  0                  0   \n",
       "3        0.0  ...                  0                  0                  0   \n",
       "4        0.0  ...                  0                  0                  0   \n",
       "\n",
       "   CAMEO_DEU_2015_8C  CAMEO_DEU_2015_8D  CAMEO_DEU_2015_9A  CAMEO_DEU_2015_9B  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   CAMEO_DEU_2015_9C  CAMEO_DEU_2015_9D  CAMEO_DEU_2015_9E  \n",
       "0                  0                  0                  0  \n",
       "1                  0                  0                  0  \n",
       "2                  0                  0                  0  \n",
       "3                  0                  0                  0  \n",
       "4                  0                  0                  0  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking that test and train data have same columns \n",
    "sum(train_data.columns==test_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012383036171500396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking total proportion of positive response from training data\n",
    "train_labels.sum()/train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Since, only 1.2% of the total responses are customers, the TRAIN-TEST split of the training data should maintain this ratio across all folds. To do this, we can use Stra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "SF1=StratifiedKFold(n_splits=7)\n",
    "SF1.get_n_splits(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor\n",
    "from xgboost.sklearn import XGBRegressor # Extreme Gradient Boosting\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',GradientBoostingRegressor())])\n",
    "pipeline2=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',AdaBoostRegressor())])\n",
    "pipeline3=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',XGBRegressor())])\n",
    "pipeline4=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',MLPRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(pipeline,column_name,train_data,train_labels,SF):\n",
    "    '''\n",
    "    To predict the predict scores of the pipeline\n",
    "    Input: \n",
    "    pipeline : model to fit \n",
    "    column_name : model name in str\n",
    "    '''\n",
    "    scores=[]\n",
    "\n",
    "    for train,test in SF.split(train_data,train_labels):\n",
    "\n",
    "        pipeline.fit(train_data.iloc[train],train_labels.iloc[train])\n",
    "\n",
    "        y_pred=pipeline.predict(train_data.iloc[test])\n",
    "\n",
    "        score=roc_auc_score(train_labels.iloc[test],y_pred)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        print(score)\n",
    "    \n",
    "    df=pd.DataFrame(scores,columns=[column_name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df1=predict_score(pipeline1,'Gradient',train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=predict_score(pipeline2,'AdaBoostRegressor',train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=predict_score(pipeline3,'XGBRegressor',train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=predict_score(pipeline4,'MLPRegressor',train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=pd.concat([df1,df2,df3,df4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk=StratifiedKFold(n_splits=2,shuffle=True)\n",
    "parameters_1={'clf__learning_rate':[0.001,0.01,1],\n",
    "             'clf__n_estimators' : [50,100,200,300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=GridSearchCV(pipeline2,param_grid=parameters_1,scoring='roc_auc',cv=sk,return_train_score=True,n_jobs=-1)\n",
    "cv.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.sum()/train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv('../capstone_data/Udacity_CUSTOMERS_052018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers=customers.drop(['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP'], axis=1)\n",
    "customers=Map_unknown_to_NAN(customers,attribute_dict)\n",
    "customers=customers.drop(columns=drop_cols,axis=1,inplace=False)\n",
    "customers=cat_to_num(customers)\n",
    "customers=mixed_categories(customers)\n",
    "customers=impute(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(customers.columns == train_data.columns).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding 5000 datapoints from customer_dataframe to train_dataframe\n",
    "\n",
    "customers['RESPONSE']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_labels=customers['RESPONSE']\n",
    "customers=customers.drop(['RESPONSE'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_part=customers.iloc[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2=pd.concat([train_data,customers_part]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_2=pd.concat([train_labels,cust_labels[:20000]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2.shape[0]==train_labels_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_2.sum()/train_labels_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indices=list(train_data_2.duplicated()[train_data_2.duplicated()==False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_2=train_labels_2.iloc[unique_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2=train_data_2.iloc[unique_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_2.sum()/train_labels_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF2=StratifiedKFold(n_splits=7)\n",
    "SF2.get_n_splits(train_data_2,train_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df1=predict_score(pipeline1,'Gradient',train_data_2,train_labels_2,SF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=predict_score(pipeline2,'AdaBoostRegressor',train_data_2,train_labels_2,SF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=predict_score(pipeline3,'XGBRegressor',train_data_2,train_labels_2,SF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2=pd.concat([df1,df2,df3],axis=1)\n",
    "scores_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline3.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk=StratifiedKFold(n_splits=2,shuffle=True)\n",
    "parameters_2={'clf__learning_rate':[0.001,0.01,0.3,1],\n",
    "             'clf__n_estimators' : [100,200,300],\n",
    "             'clf__gamma':[0.1,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=GridSearchCV(pipeline3,param_grid=parameters_2,scoring='roc_auc',cv=sk,return_train_score=True,n_jobs=-1)\n",
    "cv.fit(train_data_2,train_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBRegressor(learning_rate=0.001,n_estimators=300,gamma=0.1)\n",
    "ada=AdaBoostRegressor(n_estimators=200,learning_rate=0.001)\n",
    "final_pipeline=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline.fit(train_data_2,train_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=final_pipeline.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lnr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.read_csv('../capstone_data/Arvato_Capstone_Example_Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name ='../capstone_data/Submission_4.csv'\n",
    "f=open(name,'w')\n",
    "f.write('LNR')\n",
    "f.write(',')\n",
    "f.write('RESPONSE')\n",
    "f.write('\\n')\n",
    "\n",
    "for i in range(test_lnr.shape[0]):\n",
    "    f.write(str(test_lnr.iloc[i]))\n",
    "    f.write(',')\n",
    "    f.write(str(y_pred[i]))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
