{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn .pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv('../capstone_data/Udacity_MAILOUT_052018_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('../capstone_data/Udacity_MAILOUT_052018_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1763</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1771</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  1763         2         1.0       8.0          NaN          NaN   \n",
       "1  1771         1         4.0      13.0          NaN          NaN   \n",
       "2  1776         1         1.0       9.0          NaN          NaN   \n",
       "3  1460         2         1.0       6.0          NaN          NaN   \n",
       "4  1783         2         1.0       9.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                   8.0                 15.0  ...   \n",
       "1          NaN          NaN                  13.0                  1.0  ...   \n",
       "2          NaN          NaN                   7.0                  0.0  ...   \n",
       "3          NaN          NaN                   6.0                  4.0  ...   \n",
       "4          NaN          NaN                   9.0                 53.0  ...   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       5.0         2.0      1.0             6.0             9.0       3.0   \n",
       "1       1.0         2.0      1.0             4.0             9.0       7.0   \n",
       "2       6.0         4.0      2.0             NaN             9.0       2.0   \n",
       "3       8.0        11.0     11.0             6.0             9.0       1.0   \n",
       "4       2.0         2.0      1.0             6.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP RESPONSE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         3        0         2                    4  \n",
       "1         1        0         2                    3  \n",
       "2         3        0         1                    4  \n",
       "3         3        0         2                    4  \n",
       "4         3        0         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attribute_Unknown_Dict(path,df):\n",
    "    '''\n",
    "    Purpose: Map all the attributes to their unknown values in a dictionary\n",
    "    \n",
    "    Input: PATH TO DIAS Attributes - Values 2017.xlsx file, in str format\n",
    "    \n",
    "    Output:\n",
    "    new_dict:Dictionary with attributes as key and the unknown meaning values in a list\n",
    "    '''\n",
    "    #reading the xlsx file and storing it in a dataframe\n",
    "    attributes=pd.read_excel(path,skiprows=1)\n",
    "    \n",
    "    #formatting\n",
    "    attributes=attributes.drop(['Unnamed: 0'],axis=1,inplace=False)\n",
    "    \n",
    "    #Droping all the rows with nan values. Since, all the first values refer to the unknown meaning category\\\n",
    "    #Only keeping the first row for each attribute works\n",
    "    attributes=attributes.dropna()\n",
    "    \n",
    "    new_dict={}\n",
    "    for i in range(attributes.shape[0]):\n",
    "        #checking if it corresponds to the unknown value\n",
    "        if ('unknown' in attributes['Meaning'].iloc[i].split()) or(attributes['Meaning'].iloc[i] == 'no transaction known'):\n",
    "            new_list=[]\n",
    "            if type(attributes['Value'].iloc[i])==int:\n",
    "                new_list.append(attributes['Value'].iloc[i])\n",
    "            else:\n",
    "                for j in attributes['Value'].iloc[i].split(','):\n",
    "                    new_list.append(int(j))\n",
    "\n",
    "            new_dict[attributes['Attribute'].iloc[i]]=new_list\n",
    "    \n",
    "    #These columns are not present in  the actual dataset\n",
    "    new_dict.pop('BIP_FLAG')\n",
    "    new_dict.pop('GEOSCORE_KLS7')\n",
    "    new_dict.pop('HAUSHALTSSTRUKTUR')\n",
    "    new_dict.pop('SOHO_FLAG')\n",
    "    new_dict.pop('WACHSTUMSGEBIET_NB')\n",
    "    \n",
    "    \n",
    "    #Removing name '_RZ' from the end of each column name\n",
    "    for i in new_dict:\n",
    "        if i not in df.columns:\n",
    "            new_dict[i[:-3]]=new_dict.pop(i)\n",
    "    \n",
    "    #removing the last key_value pair\n",
    "    new_dict.pop('')\n",
    "    \n",
    "    \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Map_unknown_to_NAN(df,attribute_dict):\n",
    "    '''\n",
    "    Replace the unknown values with NAN values in the df\n",
    "    ARGS:\n",
    "    df: Dataframe on which the mapping takes place like azdias\n",
    "    attribute_dict: Dict with attribute as keys and values which are to replaced with NAN\n",
    "    \n",
    "    Output:\n",
    "    df: transformed df with more null values\n",
    "    \n",
    "    '''\n",
    "    #Replacing \n",
    "    for key,val in attribute_dict.items():\n",
    "        for j in val:\n",
    "            df[key]=df[key].replace(j,np.nan)\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num(df):\n",
    "    '''\n",
    "    converting columns which are categorical to numerical and droping other categorical columns\n",
    "    INput: \n",
    "    df: DataFrame to be processed\n",
    "    \n",
    "    Output:\n",
    "    df: After droping and converting categorical columns\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #converting CAMEO_INTL_2015 AND CAMEO_DEUB_2015 into numerical values\n",
    "    intl=[]\n",
    "    deug=[]\n",
    "    for i in range(len(df['CAMEO_INTL_2015'])):\n",
    "        if type(df['CAMEO_INTL_2015'].iloc[i])==str and df['CAMEO_INTL_2015'].iloc[i][0]=='X':\n",
    "            intl.append(np.nan)\n",
    "        else:\n",
    "            intl.append(float(df['CAMEO_INTL_2015'].iloc[i]))\n",
    "        if type(df['CAMEO_INTL_2015'].iloc[i])==str and df['CAMEO_DEUG_2015'].iloc[i][0]=='X':\n",
    "            deug.append(np.nan)\n",
    "        else:\n",
    "            deug.append(float(df['CAMEO_DEUG_2015'].iloc[i]))\n",
    "    \n",
    "    #droping the original columns\n",
    "    df=df.drop(['CAMEO_INTL_2015','CAMEO_DEUG_2015'],axis=1,inplace=False)\n",
    "    #Adding new columns\n",
    "    df['CAMEO_INTL_2015']=intl\n",
    "    df['CAMEO_DEUG_2015']=deug\n",
    "    \n",
    "    #droping 'LNR' AND 'VERDICHTUNGSRAUM' columns\n",
    "    #droping the 'LP_FAMILIE_GROB' column because it very similar 'LP_FAMILIE_FEIN'\n",
    "\n",
    "    df=df.drop(['LNR','VERDICHTUNGSRAUM','LP_FAMILIE_GROB'],axis=1,inplace=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_categories(df):\n",
    "    '''\n",
    "    Spliting mixed attributes into individua;\n",
    "    Input:\n",
    "    df: DataFrame to be processed\n",
    "    \n",
    "    Output:\n",
    "    df\n",
    "    '''\n",
    "    \n",
    "    df['WEALTH']=df['CAMEO_INTL_2015'].apply(lambda x:x/10)\n",
    "    df['LIFE_CYCLE']=df['CAMEO_INTL_2015'].apply(lambda x:x%10)\n",
    "    \n",
    "    mainstream=[1.0, 3.0, 5.0, 8.0, 10.0, 12.0, 14.0]\n",
    "    avantgarde=[2.0, 4.0, 6.0, 7.0, 9.0, 11.0, 13.0, 15.0]\n",
    "    \n",
    "    main=df['PRAEGENDE_JUGENDJAHRE'].isin([1.0, 3.0, 5.0, 8.0, 10.0, 12.0, 14.0])\n",
    "    avar=df['PRAEGENDE_JUGENDJAHRE'].isin([2.0, 4.0, 6.0, 7.0, 9.0, 11.0, 13.0, 15.0])\n",
    "    \n",
    "    df.loc[main,'MOVEMENT']=1.0\n",
    "    df.loc[avar,'MOVEMENT']=2.0\n",
    "    \n",
    "    df=df.drop(['CAMEO_INTL_2015','PRAEGENDE_JUGENDJAHRE', 'EINGEFUEGT_AM','D19_LETZTER_KAUF_BRANCHE'],axis=1,inplace=False)\n",
    "    \n",
    "    df['OST_WEST_KZ'] = df['OST_WEST_KZ'].replace({'O':1.0, 'W':2.0})\n",
    "    \n",
    "    new_df=pd.get_dummies(df,columns=['CAMEO_DEU_2015'])\n",
    "    \n",
    "    new_df=new_df.drop(['CAMEO_DEU_2015_XX'],axis=1,inplace=False)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df):\n",
    "    '''\n",
    "    Replacing all the null values with mean of the column\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    fill_mean=lambda col:col.fillna(col.mean())\n",
    "    df=df.apply(fill_mean,axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing RESPONSE column from Training_data and storing it in train_labels\n",
    "train_labels=train_data['RESPONSE']\n",
    "train_data=train_data.drop(['RESPONSE'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing cleaning functions (same as preprocessing)\n",
    "attribute_dict=Attribute_Unknown_Dict('../capstone_data/DIAS Attributes - Values 2017.xlsx',train_data)\n",
    "train_data=Map_unknown_to_NAN(train_data,attribute_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing the columns with more than 50% of null values and droping it from training_df\n",
    "drop_cols=list(train_data.isnull().sum(axis=0)[train_data.isnull().sum(axis=0)>0.50*(train_data.shape[0])]\\\n",
    "                    .reset_index()['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing cleaning functions (same as preprocessing)\n",
    "train_data=train_data.drop(columns=drop_cols,axis=1,inplace=False)\n",
    "train_data=cat_to_num(train_data)\n",
    "train_data=mixed_categories(train_data)\n",
    "train_data=impute(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>CAMEO_DEU_2015_7E</th>\n",
       "      <th>CAMEO_DEU_2015_8A</th>\n",
       "      <th>CAMEO_DEU_2015_8B</th>\n",
       "      <th>CAMEO_DEU_2015_8C</th>\n",
       "      <th>CAMEO_DEU_2015_8D</th>\n",
       "      <th>CAMEO_DEU_2015_9A</th>\n",
       "      <th>CAMEO_DEU_2015_9B</th>\n",
       "      <th>CAMEO_DEU_2015_9C</th>\n",
       "      <th>CAMEO_DEU_2015_9D</th>\n",
       "      <th>CAMEO_DEU_2015_9E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  \\\n",
       "0       2.0         1.0       8.0                   8.0                 15.0   \n",
       "1       1.0         4.0      13.0                  13.0                  1.0   \n",
       "2       1.0         1.0       9.0                   7.0                  0.0   \n",
       "3       2.0         1.0       6.0                   6.0                  4.0   \n",
       "4       2.0         1.0       9.0                   9.0                 53.0   \n",
       "\n",
       "   ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  \\\n",
       "0      0.000000         0.0           1.0                        13.0   \n",
       "1      0.000000         0.0           2.0                         1.0   \n",
       "2      0.049574         0.0           0.0                         1.0   \n",
       "3      0.000000         0.0           2.0                         4.0   \n",
       "4      0.000000         0.0           1.0                        44.0   \n",
       "\n",
       "   ANZ_TITEL  ...  CAMEO_DEU_2015_7E  CAMEO_DEU_2015_8A  CAMEO_DEU_2015_8B  \\\n",
       "0        0.0  ...                  0                  0                  0   \n",
       "1        0.0  ...                  0                  0                  0   \n",
       "2        0.0  ...                  0                  0                  0   \n",
       "3        0.0  ...                  0                  0                  0   \n",
       "4        0.0  ...                  0                  0                  0   \n",
       "\n",
       "   CAMEO_DEU_2015_8C  CAMEO_DEU_2015_8D  CAMEO_DEU_2015_9A  CAMEO_DEU_2015_9B  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   CAMEO_DEU_2015_9C  CAMEO_DEU_2015_9D  CAMEO_DEU_2015_9E  \n",
       "0                  0                  0                  0  \n",
       "1                  0                  0                  0  \n",
       "2                  0                  0                  0  \n",
       "3                  0                  0                  0  \n",
       "4                  0                  0                  0  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the LNR column for submission on Kaggle\n",
    "test_lnr=test_data['LNR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=Map_unknown_to_NAN(test_data,attribute_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping the same columns from testing data \n",
    "test_data=test_data.drop(columns=drop_cols,axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing cleaning functions (same as preprocessing)\n",
    "test_data=cat_to_num(test_data)\n",
    "test_data=mixed_categories(test_data)\n",
    "test_data=impute(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>CAMEO_DEU_2015_7E</th>\n",
       "      <th>CAMEO_DEU_2015_8A</th>\n",
       "      <th>CAMEO_DEU_2015_8B</th>\n",
       "      <th>CAMEO_DEU_2015_8C</th>\n",
       "      <th>CAMEO_DEU_2015_8D</th>\n",
       "      <th>CAMEO_DEU_2015_9A</th>\n",
       "      <th>CAMEO_DEU_2015_9B</th>\n",
       "      <th>CAMEO_DEU_2015_9C</th>\n",
       "      <th>CAMEO_DEU_2015_9D</th>\n",
       "      <th>CAMEO_DEU_2015_9E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.651514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.433248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.651514</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.433248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGER_TYP  AKT_DAT_KL   ALTER_HH  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  \\\n",
       "0  2.000000         1.0   7.000000                   6.0                  2.0   \n",
       "1  1.651514         1.0  12.433248                   0.0                 20.0   \n",
       "2  2.000000         9.0  16.000000                  11.0                  2.0   \n",
       "3  1.651514         7.0  12.433248                   0.0                  1.0   \n",
       "4  1.000000         1.0  21.000000                  13.0                  1.0   \n",
       "\n",
       "   ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  \\\n",
       "0           0.0         0.0           2.0                         2.0   \n",
       "1           0.0         0.0           1.0                        21.0   \n",
       "2           0.0         0.0           4.0                         2.0   \n",
       "3           0.0         0.0           0.0                         1.0   \n",
       "4           0.0         0.0           4.0                         1.0   \n",
       "\n",
       "   ANZ_TITEL  ...  CAMEO_DEU_2015_7E  CAMEO_DEU_2015_8A  CAMEO_DEU_2015_8B  \\\n",
       "0        0.0  ...                  0                  0                  0   \n",
       "1        0.0  ...                  0                  0                  0   \n",
       "2        0.0  ...                  0                  0                  0   \n",
       "3        0.0  ...                  0                  0                  0   \n",
       "4        0.0  ...                  0                  0                  0   \n",
       "\n",
       "   CAMEO_DEU_2015_8C  CAMEO_DEU_2015_8D  CAMEO_DEU_2015_9A  CAMEO_DEU_2015_9B  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   CAMEO_DEU_2015_9C  CAMEO_DEU_2015_9D  CAMEO_DEU_2015_9E  \n",
       "0                  0                  0                  0  \n",
       "1                  0                  0                  0  \n",
       "2                  0                  0                  0  \n",
       "3                  0                  0                  0  \n",
       "4                  0                  0                  0  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking that test and train data have same columns \n",
    "sum(train_data.columns==test_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012383036171500396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking total proportion of positive response from training data\n",
    "train_labels.sum()/train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, only 1.2% of the total responses are customers, the TRAIN-TEST split of the training data should maintain this ratio across all folds. To do this, we can use StratifiedKFold which can preserve the proportions of all categories in each fold of the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spliting data into 7 folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "SF=StratifiedKFold(n_splits=7)\n",
    "SF.get_n_splits(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, this is a regression problem, initially, we can start with GradientBoosting, AdaBoosting, XGBoost and MLP Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can define pipelines for each model\n",
    "pipeline1=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',GradientBoostingRegressor())])\n",
    "pipeline2=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',AdaBoostRegressor())])\n",
    "pipeline3=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',XGBRegressor())])\n",
    "pipeline4=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',MLPRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(pipeline,column_name):\n",
    "    '''\n",
    "    To predict the predict scores of the pipeline\n",
    "    Input: \n",
    "    pipeline : model to fit \n",
    "    column_name : model name in str\n",
    "    '''\n",
    "    scores=[]\n",
    "\n",
    "    for train,test in SF.split(train_data,train_labels):\n",
    "\n",
    "        pipeline.fit(train_data.iloc[train],train_labels.iloc[train])\n",
    "\n",
    "        y_pred=pipeline.predict(train_data.iloc[test])\n",
    "\n",
    "        score=roc_auc_score(train_labels.iloc[test],y_pred)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        print(score)\n",
    "    \n",
    "    df=pd.DataFrame(scores,columns=[column_name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7094247599367934\n",
      "0.7768768775286947\n",
      "0.7390625813957526\n",
      "0.7842537274550838\n",
      "0.7805620924113617\n",
      "0.7158710999574501\n",
      "0.7697053638881894\n"
     ]
    }
   ],
   "source": [
    " df1=predict_score(pipeline1,'Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885907030856586\n",
      "0.7483471235826287\n",
      "0.7400263071072601\n",
      "0.7720412646862165\n",
      "0.7613951145807102\n",
      "0.7185478338644831\n",
      "0.7561024322892697\n"
     ]
    }
   ],
   "source": [
    "df2=predict_score(pipeline2,'AdaBoostRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5713905867439962\n",
      "0.5903525412839259\n",
      "0.6008894927850805\n",
      "0.6545949513281638\n",
      "0.597758316762042\n",
      "0.6106546166604434\n",
      "0.626901718493561\n"
     ]
    }
   ],
   "source": [
    "df3=predict_score(pipeline3,'XGBRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6100264373404642\n",
      "0.47835849728246715\n",
      "0.5860114344753339\n",
      "0.5773115865889769\n",
      "0.5491505223213123\n",
      "0.500973653817765\n",
      "0.5433107703262445\n"
     ]
    }
   ],
   "source": [
    "df4=predict_score(pipeline4,'MLPRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinating all the scores in a dataframe for each model\n",
    "scores=pd.concat([df1,df2,df3,df4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient</th>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>MLPRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.753680</td>\n",
       "      <td>0.740722</td>\n",
       "      <td>0.607506</td>\n",
       "      <td>0.549306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031765</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>0.046947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.709425</td>\n",
       "      <td>0.688591</td>\n",
       "      <td>0.571391</td>\n",
       "      <td>0.478358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.727467</td>\n",
       "      <td>0.729287</td>\n",
       "      <td>0.594055</td>\n",
       "      <td>0.522142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.769705</td>\n",
       "      <td>0.748347</td>\n",
       "      <td>0.600889</td>\n",
       "      <td>0.549151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.778719</td>\n",
       "      <td>0.758749</td>\n",
       "      <td>0.618778</td>\n",
       "      <td>0.581662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.784254</td>\n",
       "      <td>0.772041</td>\n",
       "      <td>0.654595</td>\n",
       "      <td>0.610026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gradient  AdaBoostRegressor  XGBRegressor  MLPRegressor\n",
       "count  7.000000           7.000000      7.000000      7.000000\n",
       "mean   0.753680           0.740722      0.607506      0.549306\n",
       "std    0.031765           0.028615      0.026897      0.046947\n",
       "min    0.709425           0.688591      0.571391      0.478358\n",
       "25%    0.727467           0.729287      0.594055      0.522142\n",
       "50%    0.769705           0.748347      0.600889      0.549151\n",
       "75%    0.778719           0.758749      0.618778      0.581662\n",
       "max    0.784254           0.772041      0.654595      0.610026"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch on Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('clf',\n",
       "   GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                             init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=None, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'clf': GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                           init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'clf__alpha': 0.9,\n",
       " 'clf__ccp_alpha': 0.0,\n",
       " 'clf__criterion': 'friedman_mse',\n",
       " 'clf__init': None,\n",
       " 'clf__learning_rate': 0.1,\n",
       " 'clf__loss': 'ls',\n",
       " 'clf__max_depth': 3,\n",
       " 'clf__max_features': None,\n",
       " 'clf__max_leaf_nodes': None,\n",
       " 'clf__min_impurity_decrease': 0.0,\n",
       " 'clf__min_impurity_split': None,\n",
       " 'clf__min_samples_leaf': 1,\n",
       " 'clf__min_samples_split': 2,\n",
       " 'clf__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__n_estimators': 100,\n",
       " 'clf__n_iter_no_change': None,\n",
       " 'clf__presort': 'deprecated',\n",
       " 'clf__random_state': None,\n",
       " 'clf__subsample': 1.0,\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__validation_fraction': 0.1,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk=StratifiedKFold(n_splits=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_1={'clf__learning_rate':[0.001,0.01,0.1,1],\n",
    "             'clf__n_estimators' : [50,100,200,300],\n",
    "             'clf__max_depth':[3,5,7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('clf',\n",
       "                                        GradientBoostingRegressor(alpha=0.9,\n",
       "                                                                  ccp_alpha=0.0,\n",
       "                                                                  criterion='friedman_mse',\n",
       "                                                                  init=None,\n",
       "                                                                  learning_rate=0.1,\n",
       "                                                                  loss='ls',\n",
       "                                                                  max_depth=3,\n",
       "                                                                  max_features=None,\n",
       "                                                                  max_l...\n",
       "                                                                  presort='deprecated',\n",
       "                                                                  random_state=None,\n",
       "                                                                  subsample=1.0,\n",
       "                                                                  tol=0.0001,\n",
       "                                                                  validation_fraction=0.1,\n",
       "                                                                  verbose=0,\n",
       "                                                                  warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__learning_rate': [0.001, 0.01, 0.1, 1],\n",
       "                         'clf__max_depth': [3, 5, 7],\n",
       "                         'clf__n_estimators': [50, 100, 200, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1=GridSearchCV(pipeline1,param_grid=parameters_1,scoring='roc_auc',cv=sk,return_train_score=True,n_jobs=-1)\n",
    "cv1.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 100}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647269097797522"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch on AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('clf',\n",
       "   AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                     n_estimators=50, random_state=None))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'clf': AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                   n_estimators=50, random_state=None),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'clf__base_estimator': None,\n",
       " 'clf__learning_rate': 1.0,\n",
       " 'clf__loss': 'linear',\n",
       " 'clf__n_estimators': 50,\n",
       " 'clf__random_state': None}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_2={'clf__learning_rate':[0.001,0.01,0.1,1],\n",
    "             'clf__n_estimators' : [50,100,200,300],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('clf',\n",
       "                                        AdaBoostRegressor(base_estimator=None,\n",
       "                                                          learning_rate=1.0,\n",
       "                                                          loss='linear',\n",
       "                                                          n_estimators=50,\n",
       "                                                          random_state=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__learning_rate': [0.001, 0.01, 0.1, 1],\n",
       "                         'clf__n_estimators': [50, 100, 200, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2=GridSearchCV(pipeline2,param_grid=parameters_2,scoring='roc_auc',cv=sk,return_train_score=True,n_jobs=-1)\n",
    "cv2.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.001, 'clf__n_estimators': 200}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685017250881151"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch on XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('clf',\n",
       "   XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                importance_type='gain', interaction_constraints='',\n",
       "                learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "                n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "                objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "                reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "                validate_parameters=1, verbosity=None))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'clf': XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'clf__objective': 'reg:squarederror',\n",
       " 'clf__base_score': 0.5,\n",
       " 'clf__booster': 'gbtree',\n",
       " 'clf__colsample_bylevel': 1,\n",
       " 'clf__colsample_bynode': 1,\n",
       " 'clf__colsample_bytree': 1,\n",
       " 'clf__gamma': 0,\n",
       " 'clf__gpu_id': -1,\n",
       " 'clf__importance_type': 'gain',\n",
       " 'clf__interaction_constraints': '',\n",
       " 'clf__learning_rate': 0.300000012,\n",
       " 'clf__max_delta_step': 0,\n",
       " 'clf__max_depth': 6,\n",
       " 'clf__min_child_weight': 1,\n",
       " 'clf__missing': nan,\n",
       " 'clf__monotone_constraints': '()',\n",
       " 'clf__n_estimators': 100,\n",
       " 'clf__n_jobs': 0,\n",
       " 'clf__num_parallel_tree': 1,\n",
       " 'clf__random_state': 0,\n",
       " 'clf__reg_alpha': 0,\n",
       " 'clf__reg_lambda': 1,\n",
       " 'clf__scale_pos_weight': 1,\n",
       " 'clf__subsample': 1,\n",
       " 'clf__tree_method': 'exact',\n",
       " 'clf__validate_parameters': 1,\n",
       " 'clf__verbosity': None}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline3.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_3={'clf__learning_rate':[0.001,0.01,0.3,1],'clf__gamma':[0.1,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=None, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('clf',\n",
       "                                        XGBRegressor(base_score=0.5,\n",
       "                                                     booster='gbtree',\n",
       "                                                     colsample_bylevel=1,\n",
       "                                                     colsample_bynode=1,\n",
       "                                                     colsample_bytree=1,\n",
       "                                                     gamma=0, gpu_id=-1,\n",
       "                                                     importance_type='gain',\n",
       "                                                     inte...\n",
       "                                                     objective='reg:squarederror',\n",
       "                                                     random_state=0,\n",
       "                                                     reg_alpha=0, reg_lambda=1,\n",
       "                                                     scale_pos_weight=1,\n",
       "                                                     subsample=1,\n",
       "                                                     tree_method='exact',\n",
       "                                                     validate_parameters=1,\n",
       "                                                     verbosity=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__gamma': [0.1, 0, 1],\n",
       "                         'clf__learning_rate': [0.001, 0.01, 0.3, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3=GridSearchCV(pipeline3,param_grid=parameters_3,scoring='roc_auc',cv=sk,return_train_score=True,n_jobs=-1)\n",
    "cv3.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__gamma': 0, 'clf__learning_rate': 0.01}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.762674967527232"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After gridsearch on all the three models, final model for each boosting type was created and tested on Kaggle. Currently, AdaBoosting model produces a 79.99% accuracy on the Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb=GradientBoostingRegressor(learning_rate=0.01,max_depth=3,n_estimators=100)\n",
    "ada=AdaBoostRegressor(learning_rate=0.001,n_estimators=200)\n",
    "xgb=XGBRegressor(learning_rate=0.01,gamma=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model,name):\n",
    "    '''\n",
    "    Function to generate submission csv file\n",
    "    Input: model after GridSearch\n",
    "    name: name of the csv file\n",
    "    \n",
    "    Output: None\n",
    "    Submission file will be saved in a particular location\n",
    "    '''\n",
    "    pipeline=Pipeline([('scaler',StandardScaler()),\n",
    "                   ('clf',model)])\n",
    "    \n",
    "    pipeline.fit(train_data,train_labels)\n",
    "    \n",
    "    y_pred=pipeline.predict(test_data)\n",
    "    \n",
    "    name ='../capstone_data/' + name +'.csv'\n",
    "    f=open(name,'w')\n",
    "    f.write('LNR')\n",
    "    f.write(',')\n",
    "    f.write('RESPONSE')\n",
    "    f.write('\\n')\n",
    "\n",
    "    for i in range(test_lnr.shape[0]):\n",
    "        f.write(str(test_lnr.iloc[i]))\n",
    "        f.write(',')\n",
    "        f.write(str(y_pred[i]))\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(gb,'Submission_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(ada,'Submission_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(xgb,'Submission_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
